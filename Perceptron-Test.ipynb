{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import shuffle\n",
    "from random import seed\n",
    "\n",
    "from device import Device\n",
    "from stroke import Stroke\n",
    "from sample import Sample\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import sklearn.utils\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySample:\n",
    "    def __init__(self, events, sequence_counter, count, inch, jump):\n",
    "        self.angle = 0\n",
    "        self.inch = inch\n",
    "\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.time = []\n",
    "        for i in range(sequence_counter, sequence_counter+count):\n",
    "            if i >= jump-1:\n",
    "                self.x.append(events[jump-1][0])\n",
    "                self.y.append(events[jump-1][1])\n",
    "                \n",
    "                if i == sequence_counter:\n",
    "                    self.time.append(17)\n",
    "                else:\n",
    "                    self.time.append(events[jump-1][3]-events[jump-2][3])\n",
    "            else:\n",
    "                self.x.append(events[i][0])\n",
    "                self.y.append(events[i][1])\n",
    "                if i == sequence_counter:\n",
    "                    self.time.append(17)\n",
    "                else:\n",
    "                    self.time.append(events[i][3]-events[i-1][3])\n",
    "\n",
    "    def derivate(self):\n",
    "        x_der = []\n",
    "        y_der = []\n",
    "        time_der = []\n",
    "        for i in range(len(self.x)-1):\n",
    "            x_der.append(self.x[i+1]-self.x[i])\n",
    "            y_der.append(self.y[i+1]-self.y[i])\n",
    "            time_der.append(self.time[i+1])\n",
    "        self.x = x_der\n",
    "        self.y = y_der\n",
    "        self.time = time_der\n",
    "\n",
    "    def getAngle(self, startIndex, endIndex):\n",
    "        myX = self.x[endIndex]-self.x[startIndex]\n",
    "        myY = self.y[endIndex]-self.y[startIndex]\n",
    "        return math.atan2(myX, myY)\n",
    "\n",
    "    def rotate(self, angle, originIndex):\n",
    "        self.rotation = angle\n",
    "\n",
    "        cs = math.cos(angle)\n",
    "        sn = math.sin(angle)\n",
    "        for i in range(len(self.x)):\n",
    "            myX = (self.x[i]-self.x[originIndex]) * cs -\\\n",
    "                (self.y[i]-self.y[originIndex])*sn\n",
    "            myY = (self.x[i]-self.x[originIndex]) * sn +\\\n",
    "                (self.y[i]-self.y[originIndex])*cs\n",
    "            self.x[i] = myX + self.x[originIndex]\n",
    "            self.y[i] = myY + self.y[originIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadStudyData(path, inType, sampleLength):\n",
    "    file_list = []\n",
    "    name = \"xxx\"\n",
    "    if inType == 1: name = \"FittsTasks-participant\"\n",
    "    elif inType == 2: name = \"PaintTasks-participant\"\n",
    "    elif inType == 3: name = \"WriteTasks-participant\"\n",
    "\n",
    "    fileName = path+name\n",
    "\n",
    "    for index in range(1,9):\n",
    "        file_list.append(fileName+str(index)+\".txt\")\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for fileName in file_list:\n",
    "        events = []\n",
    "        f = open(fileName, 'r')\n",
    "        for line in f:\n",
    "            tokens = line.split(';')\n",
    "            events.append([float(tokens[2]), float(tokens[3]), float(tokens[4]), int(tokens[1]), int(tokens[5])])\n",
    "\n",
    "        seqCount = 0\n",
    "        for i, event in enumerate(events):\n",
    "            jump = i+sampleLength+1\n",
    "\n",
    "            for j in range(i, i+sampleLength):\n",
    "                if j >= len(events) or  events[j][4] is not 2:\n",
    "                    jump = j\n",
    "                    break\n",
    "            if jump-i > 11:\n",
    "                sample = MySample(events, i, sampleLength, 7, jump)\n",
    "\n",
    "                sample.angle = sample.getAngle(9, 10) + math.radians(45)\n",
    "                sample.rotate(sample.angle, 10)\n",
    "\n",
    "                sample.derivate()\n",
    "\n",
    "                sameTime = 0\n",
    "                for a in range(len(sample.time)):\n",
    "                    if sample.time[a] < 1:\n",
    "                        sameTime = 1\n",
    "                if sameTime == 0:\n",
    "                    samples.append(sample)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildModel(x, n_input, n_output, keep_prob):\n",
    "    weights = {\n",
    "        'h1': tf.get_variable('h1', shape=(n_input, 4096), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'h2': tf.get_variable('h2', shape=(4096, 2048), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'h3': tf.get_variable('h3', shape=(2048, 1024), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'h4': tf.get_variable('h4', shape=(1024, 512), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'out': tf.Variable(tf.random_normal([512, n_output]))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([4096])),\n",
    "        'b2': tf.Variable(tf.random_normal([2048])),\n",
    "        'b3': tf.Variable(tf.random_normal([1024])),\n",
    "        'b4': tf.Variable(tf.random_normal([512])),\n",
    "        'out': tf.Variable(tf.random_normal([n_output]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    layer_3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    layer_4 = tf.nn.dropout(layer_4, keep_prob)\n",
    "\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer, weights\n",
    "\n",
    "def buildPerceptron():\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "    x = tf.placeholder(\"float\", [None, 33])\n",
    "    y = tf.placeholder(\"float\", [None, 2])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    pred, weights = buildModel(x, 33, 2, keep_prob)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.pow(pred - y, 2))\n",
    "    cost = cost + tf.sqrt(cost + 0.0000001)\n",
    "    cost = tf.reduce_mean(cost +\n",
    "        0.5*tf.nn.l2_loss(weights['h1']) +\n",
    "        0.5*tf.nn.l2_loss(weights['h2']) +\n",
    "        0.5*tf.nn.l2_loss(weights['h3']) +\n",
    "        0.5*tf.nn.l2_loss(weights['h4']) +\n",
    "        0.5*tf.nn.l2_loss(weights['out']))\n",
    "    perf = tf.sqrt(tf.reduce_sum(tf.pow(pred - y, 2)))\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    return init, saver, pred, x, y, keep_prob\n",
    "\n",
    "def buildPerceptronVectors(samples, steps):\n",
    "    inStudyVec = []\n",
    "    outStudyVec = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        line = []\n",
    "        for i in range(10):\n",
    "            line.append(sample.x[i])\n",
    "            line.append(sample.y[i])\n",
    "            line.append(sample.time[i])\n",
    "\n",
    "        myTime = 0\n",
    "        for i in range(10, 10+steps):\n",
    "            myTime = myTime + sample.time[i]\n",
    "\n",
    "        line.append(myTime)\n",
    "        line.append(sample.angle)\n",
    "        line.append(sample.inch)\n",
    "\n",
    "        inStudyVec.append(line)\n",
    "\n",
    "        x = 0\n",
    "        y = 0\n",
    "        for i in range(0,steps):\n",
    "            x = x + sample.x[10 + i]\n",
    "            y = y + sample.y[10 + i]\n",
    "        outStudyVec.append([x, y])\n",
    "\n",
    "    inStudyVec = np.array(inStudyVec)\n",
    "    outStudyVec = np.array(outStudyVec)\n",
    "\n",
    "    return inStudyVec, outStudyVec\n",
    "\n",
    "def getPerceptronPerformance(sess, pred, x, y, keep_prob, inVec, outVec):    \n",
    "    batch_size = 500\n",
    "    total_batch = int(len(inVec)/batch_size)\n",
    "    avgDist = 0\n",
    "    for i in range(int(len(inVec)/batch_size)+1):\n",
    "        batch_x = inVec[i*batch_size:min((i+1)*batch_size, len(inVec))]\n",
    "        batch_y = outVec[i*batch_size:min((i+1)*batch_size, len(inVec))]\n",
    "\n",
    "        c = sess.run(pred, feed_dict={x: batch_x, y: batch_y, keep_prob: 1})\n",
    "        for j in range(len(batch_x)):                \n",
    "            dist = (batch_y[j][0]-c[j][0])*(batch_y[j][0]-c[j][0])\n",
    "            dist = dist + (batch_y[j][1]-c[j][1])*(batch_y[j][1]-c[j][1])\n",
    "            dist = math.sqrt(dist)\n",
    "            avgDist = avgDist + dist\n",
    "    return avgDist / len(inVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Perceptron 33\n",
      "33.33 ms  fitts 8.7 px\n",
      "33.33 ms  draw 14.3 px\n",
      "33.33 ms  write 5.6 px\n",
      "33.33 ms  average 9.5 px\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/Perceptron 67\n",
      "66.67 ms  fitts 16.8 px\n",
      "66.67 ms  draw 32.8 px\n",
      "66.67 ms  write 13.0 px\n",
      "66.67 ms  average 20.8 px\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/Perceptron 100\n",
      "100.00 ms  fitts 27.8 px\n",
      "100.00 ms  draw 55.4 px\n",
      "100.00 ms  write 23.1 px\n",
      "100.00 ms  average 35.4 px\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tasks = [\"fitts\", \"draw\", \"write\"]\n",
    "time = [\"Perceptron 33\", \"Perceptron 67\", \"Perceptron 100\"]\n",
    "\n",
    "init, saver, pred, x, y, keep_prob = buildPerceptron()\n",
    "for j1, store in enumerate(time):\n",
    "    j = (j1+1) * 2\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver.restore(sess, \"./models/\"+store)\n",
    "        avgError = 0\n",
    "        for i in range(1,4):\n",
    "            samples = loadStudyData('./data/', i, 11+j)\n",
    "            inStudyVec, outStudyVec = buildPerceptronVectors(samples, j)\n",
    "            \n",
    "            perf = getPerceptronPerformance(sess, pred, x, y, keep_prob, inStudyVec, outStudyVec)\n",
    "            avgError = avgError + perf\n",
    "\n",
    "            print(\"{:.2f}\".format(j*16.6666), \"ms \", tasks[i-1], \"{:.1f}\".format(perf), \"px\")\n",
    "        print(\"{:.2f}\".format(j*16.6666), \"ms \", \"average\", \"{:.1f}\".format(avgError/3), \"px\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
